{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U08URC_kDyzW"
   },
   "source": [
    "___\n",
    "\n",
    "<a href=\"https://lms.clarusway.com/mod/lesson/view.php?id=8514&pageid=8158&startlastseen=no\"><img align=\"center\" src=\"https://i.ibb.co/6Z5pQxD/lmss.png\" alt=\"Open in Clarusway LMS\" width=\"70\" height=\"200\" title=\"Open Clarusway Learning Management Sytem\"></a>\n",
    "\n",
    "<a href=\"https://github.com/clarusway/DS-DE-0322-Students/blob/main/3-%20Classes%26Labs/2-DAwPY/DAwPy_S03_(Pandas_Series).ipynb\"><img align=\"left\" src=\"https://i.ibb.co/n3HWyQX/github-logo.png\" alt=\"Open in Clarusway GitHub\" width=\"100\" height=\"150\" title=\"Open and Execute in Clarusway GitHub Repository\"></a>\n",
    "\n",
    "<a href=\"https://nbviewer.org/github/4dsolutions/clarusway_data_analysis/blob/main/DAwPy_S3_%28Pandas_Series%29/DAwPy_S3_%28Pandas_Series%29.ipynb\"><img align=\"right\" src=\"https://i.ibb.co/48wtV8c/nbviewer-badge.png\" alt=\"Open in nbviewer\" width=\"130\" height=\"200\" title=\"Open and Execute in nbviewer\"></a><br/>\n",
    "___\n",
    "\n",
    "<a href=\"https://clarusway.com/\"><img align=\"center\" src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" alt=\"CLRSWY\" width=\"450\" height=\"200\" title=\"Welcome to Place Where You can Reinvent Yourself\"></a><br/>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#9d4f8c; font-size:120%; text-align:center; border-radius:10px 10px;\">Way to Reinvent Yourself</p>\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://i.ibb.co/99DQ3TY/DS-Courses.png\" class=\"img-fluid\" \n",
    "alt=\"CLRSWY\"></p>\n",
    "\n",
    "\n",
    "<img src=https://i.ibb.co/6gCsHd6/1200px-Pandas-logo-svg.png width=\"700\" height=\"200\">\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:200%; text-align:center; border-radius:10px 10px;\">Data Analysis with Python</p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:150%; text-align:center; border-radius:10px 10px;\">Session - 07</p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#4d77cf; font-size:200%; text-align:center; border-radius:10px 10px;\">Handling with Missing Values</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://i.ibb.co/RgknJfB/missing-value.png width=\"700\" height=\"200\">\n",
    "\n",
    "\n",
    "**[Working with Missing Data in Pandas](https://pandas.pydata.org/docs/user_guide/missing_data.html)**\n",
    "\n",
    "Missing Data can occur when no information is provided for one or more items or for a whole unit. Missing Data is a very big problem in a real-life scenarios. Missing Data can also refer to as NA (an acronym for Not Available) values in Pandas. In DataFrame sometimes many datasets simply arrive with missing data, either because it exists and was not collected or it never existed. \n",
    "\n",
    "**[When and Why Is Data Missed?](https://www.tutorialspoint.com/python_pandas/python_pandas_missing_data.htm)**\n",
    "\n",
    "Let us consider an online survey where different users being surveyed for a product. Many a times, people do not share all the information related to them. For Example, different users being surveyed may choose not to share their income, some users may choose not to share the address. Few people share their experience, but not how long they are using the product; few people share how long they are using the product, their experience but not their contact information. Thus, in some or the other way a part of data is always missing, and this is very common in real time.\n",
    "\n",
    "\n",
    "**[Missing Value Handling Methods](https://becominghuman.ai/imputing-missing-values-f00a770d9cc4)**\n",
    "\n",
    "- **``Delete all instances with at least a missing value``**: If you do this method then, the size of the dataset should be large enough to represent the population without those instances.<br>\n",
    "- **``Recover redoing the experiment or contacting the subject``**: This is one of the high-cost methods to recover the values, redoing an experiment takes time and cost money, moreover if it's a public opinion kind of dataset, then acts like GDPR restrict future uses to contact the subject in some cases.<br>\n",
    "- **``Domain Experts Guessing``**: By consulting the domain experts it is possible to guess the missing values with their experience but this method is a hectic and highly cost method due to the high hourly rates of experts.<br>\n",
    "- **``Fill with mean``**: This is one of the easiest and most primary methods of imputing missing values, by filling each missing value with the average of the attribute. This is not always good to use because it reduces the variability of the data but in some cases makes sense.<br>\n",
    "- **``Fill with median``**: Similar to the above method the problem is it reduces the variability of the data. Moreover, if the missing values are distributed then it could increase the noise of the data as well.<br>\n",
    "- **``Using Machine Learning algorithms``**: There are two different ways of using ML for imputation, first the multiple-regression analysis, by creating a regression equation using the rest of the data it is possible to predict missing values. This method needs more complete instances to train the model. Finally, the most common and popular method is the Multiple Imputation. where there are multiple missing values based on the correlations for the missing data and then averages the simulated datasets by incorporating random errors in your predictions\n",
    "\n",
    "[YouTube Video Source: Python Pandas Tutorial: Handle Missing Data; fillna, dropna, interpolate](https://www.youtube.com/watch?v=EaGbS7eWSs0)<br>\n",
    "[YouTube Video Source: Python Pandas Tutorial: Handle Missing Data; replace function](https://www.youtube.com/watch?v=XOxABiMhG2U)<br>\n",
    "[YouTube Video Source: Handling Missing Values in Pandas Dataframe](https://www.youtube.com/watch?v=uDr67HBIPz8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vnM00e0DyzX"
   },
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "## <p style=\"background-color:#9d4f8c; font-family:newtimeroman; color:#FFF9ED; font-size:175%; text-align:center; border-radius:10px 10px;\">Content</p>\n",
    "\n",
    "* [IMPORTING LIBRARIES NEEDED IN THIS NOTEBOOK](#0)\n",
    "* [TYPE OF NAN VALUES](#1)\n",
    "* [DETECTING MISSING VALUES](#2)\n",
    "* [CONVERTING INAPPROPRIATE VALUES TO NAN VALUES](#3)    \n",
    "* [MISSING VALUE HANDLING METHODS](#4)    \n",
    "* [THE END OF THE SESSION - 07](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30XgnYRTDyzX"
   },
   "source": [
    "## <p style=\"background-color:#9d4f8c; font-family:newtimeroman; color:#FFF9ED; font-size:175%; text-align:center; border-radius:10px 10px;\">Importing Libraries Needed in This Notebook</p>\n",
    "\n",
    "<a id=\"0\"></a>\n",
    "<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" \n",
    "style=\"color:blue; background-color:#dfa8e4\" data-toggle=\"popover\">Content</a>\n",
    "\n",
    "Once you've installed NumPy & Pandas you can import them as a library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-bhPlyEyDyzY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")  # to suppress all warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tbH43uTM98fP",
    "outputId": "05e86669-82f3-425c-8478-14a47097b792"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>status</th>\n",
       "      <th>dept</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>M</td>\n",
       "      <td>FT</td>\n",
       "      <td>DS</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>F</td>\n",
       "      <td>PT</td>\n",
       "      <td>FS</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>AWS</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>F</td>\n",
       "      <td>FT</td>\n",
       "      <td>AWS</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>M</td>\n",
       "      <td>PT</td>\n",
       "      <td>DS</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>F</td>\n",
       "      <td>PT</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P007</td>\n",
       "      <td>M</td>\n",
       "      <td>FT</td>\n",
       "      <td>FS</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P008</td>\n",
       "      <td>F</td>\n",
       "      <td>-</td>\n",
       "      <td>FS</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P009</td>\n",
       "      <td>M</td>\n",
       "      <td>PT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P010</td>\n",
       "      <td>F</td>\n",
       "      <td>FT</td>\n",
       "      <td>DS</td>\n",
       "      <td>-</td>\n",
       "      <td>7.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P011</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender status  dept var1  var2 salary\n",
       "0   P001      M     FT    DS    2   8.0    NaN\n",
       "1   P002      F     PT    FS    3   NaN     54\n",
       "2   P003      M      -   AWS    5   5.0     59\n",
       "3   P004      F     FT   AWS  nan   8.0    120\n",
       "4   P005      M     PT    DS    7  11.0     58\n",
       "5   P006      F     PT  None    1   NaN     75\n",
       "6   P007      M     FT    FS  nan   NaN   None\n",
       "7   P008      F      -    FS   10   2.0    136\n",
       "8   P009      M     PT   NaN   14   3.0     60\n",
       "9   P010      F     FT    DS    -   7.0    125\n",
       "10  P011      M    NaN   AWS    6   9.0    NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_no = [\"P001\", \"P002\", \"P003\", \"P004\", \"P005\", \"P006\", \"P007\", \"P008\", \"P009\", \"P010\", \"P011\"]\n",
    "gender = [\"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\"]\n",
    "status = [\"FT\", \"PT\", \"-\", \"FT\", \"PT\", \"PT\", \"FT\", \"-\", \"PT\", \"FT\", np.nan]\n",
    "dept = [\"DS\", \"FS\", \"AWS\", \"AWS\", \"DS\", None, \"FS\", \"FS\", np.nan, \"DS\", \"AWS\"]\n",
    "\n",
    "V1 = np.array([2, 3, 5, np.nan, 7, 1, np.nan, 10, 14, \"-\", 6])\n",
    "V2 = np.array([8, np.nan, 5, 8, 11, np.nan, np.nan, 2, 3, 7, 9])\n",
    "salary = np.array([np.nan, 54, 59, 120, 58, 75, None, 136, 60, 125, np.nan])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\n",
    "                   \"id\" : id_no,\n",
    "                   \"gender\": gender,\n",
    "                   \"status\": status,\n",
    "                   \"dept\": dept,\n",
    "                   \"var1\" : V1,\n",
    "                   \"var2\" : V2,\n",
    "                   \"salary\" : salary\n",
    "                  })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hs6sPY5O98fR"
   },
   "source": [
    "## <p style=\"background-color:#9d4f8c; font-family:newtimeroman; color:#FFF9ED; font-size:175%; text-align:center; border-radius:10px 10px;\">Type of NaN Values</p>\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" \n",
    "style=\"color:blue; background-color:#dfa8e4\" data-toggle=\"popover\">Content</a>\n",
    "\n",
    "**[Values considered ‚Äúmissing‚Äù](https://pandas.pydata.org/docs/user_guide/missing_data.html)**\n",
    "\n",
    "As data comes in many shapes and forms, Pandas aims to be flexible with regard to handling missing data. While **``NaN``** is the **default missing value marker** for reasons of **computational speed and convenience**, we need to be able to easily detect this value with data of different types: floating point, integer, boolean, and general object. In many cases, however, the Python **``None``** will arise and we wish to also consider that ‚Äúmissing‚Äù or ‚Äúnot available‚Äù or ‚ÄúNA‚Äù.\n",
    "\n",
    "**In Pandas missing data is represented by two value:**\n",
    "\n",
    "- **``None``**: None is a Python singleton object that is often used for missing data in Python code.\n",
    "- **``NaN ``**: NaN (an acronym for Not a Number), is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation\n",
    "\n",
    "[Data Cleaning with Python and Pandas: Detecting Missing Values](https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b)<br>\n",
    "[8 Methods For Handling Missing Values With Python Pandas](https://towardsdatascience.com/8-methods-for-handling-missing-values-with-python-pandas-842544cdf891)<br>\n",
    "[Missing values in pandas (nan, None, pd.NA)](https://note.nkmk.me/en/python-pandas-nan-none-na/)<br>\n",
    "[Handling Missing Data](https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html)<br>\n",
    "[Practical Strategies to Handle Missing Values](https://towardsdatascience.com/practical-strategies-to-handle-missing-values-626f9c43870b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us first examine the Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``NoneType``** in Python is the data type of the object when the object does not have any value.\n",
    "\n",
    "**When is NoneType used?**\n",
    "\n",
    "It is useful in many places. It is the default return type of the function when the function does not return any value.\n",
    "\n",
    "**Use cases (Examples):**\n",
    "\n",
    "- If the Python regular expression in re.search does not match, it returns NoneType object.\n",
    "- When you search key in the Python dictionary and the key is not present, it returns NoneType object.\n",
    "- The None keyword is also used for matching or identifying if a certain function returns any value or not.\n",
    "\n",
    "[What is NoneType in Python and Null Equivalent?](https://www.csestack.org/nonetype-in-python-null/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us examine the **Null values** in **``\"salary\"``**, **``\"status\"``**, and **``\"var1\"``** features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therfore, it can be concluded that it is so important how any null values came out; are they created by means of list or np.array, etc.?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "True\n",
      "False\n",
      "False\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(0 * np.nan)\n",
    "print(np.nan is np.nan )\n",
    "print(np.nan == np.nan)\n",
    "print(np.inf > np.nan)\n",
    "print(np.nan - np.nan)\n",
    "print(np.nan + np.nan)\n",
    "print(np.nan - 10)\n",
    "print(np.nan + 10)\n",
    "print(np.nan in set([np.nan]))\n",
    "print(0.3 == 3 * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2395656983280\n",
      "2395656983280\n"
     ]
    }
   ],
   "source": [
    "a = np.nan\n",
    "b = np.nan\n",
    "print(id(a))\n",
    "print(id(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``nan``** not being equal to nan is part of the definition of nan, so that part's easy.\n",
    "\n",
    "As for **``nan``** in [nan] being True, that's because identity is tested before equality for containment in lists. You're comparing the same two objects.\n",
    "\n",
    "The reason for this is that **``== operator``** compares the values of both the operands and checks for value equality. **``is operator``**, on the other hand, checks whether both the operands refer to the same object or not.\n",
    "\n",
    "In fact, you can print out the **IDs** of both **a** and **b** and see that they **refer to the same object**.\n",
    "\n",
    "**What is the None keyword in Python? [ANSWER01](https://www.educative.io/edpresso/what-is-the-none-keyword-in-python), [ANSWER02](https://stackoverflow.com/questions/21095654/what-is-a-nonetype-object)**\n",
    "\n",
    "**Difference between None and NaN in Pandas [ANSWER01](https://www.skytowner.com/explore/difference_between_none_and_nan_in_pandas), [ANSWER02](https://kegui.medium.com/what-is-the-difference-between-nan-none-pd-nan-and-np-nan-a8ee0532e2eb)**\n",
    "\n",
    "**Difference between np.nan and np.NaN [ANSWER](https://stackoverflow.com/questions/53436339/difference-between-np-nan-and-np-nan)**\n",
    "\n",
    "**Difference between nan and 'nan' in Python [ANSWER01](https://stackoverflow.com/questions/40309789/difference-between-nan-and-nan-in-python), [ANSWER02](https://towardsdatascience.com/navigating-the-hell-of-nans-in-python-71b12558895b)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3Bf1wQ_98fd"
   },
   "source": [
    "## <p style=\"background-color:#9d4f8c; font-family:newtimeroman; color:#FFF9ED; font-size:175%; text-align:center; border-radius:10px 10px;\">Detecting Missing Values</p>\n",
    "\n",
    "<a id=\"2\"></a>\n",
    "<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" \n",
    "style=\"color:blue; background-color:#dfa8e4\" data-toggle=\"popover\">Content</a>\n",
    "\n",
    "**``NaN``**, standing for **\"Not A Number\"**, is a numeric data type used to represent any value that is undefined or unpresentable.\n",
    "\n",
    "For example, 0/0 is undefined as a real number and is, therefore, represented by NaN. The square root of a negative number is an imaginary number that cannot be represented as a real number, so, it is represented by NaN.\n",
    "\n",
    "**``NaN``** is also assigned to variables, in a computation, that do not have values and have yet to be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>status</th>\n",
       "      <th>dept</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>M</td>\n",
       "      <td>FT</td>\n",
       "      <td>DS</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>F</td>\n",
       "      <td>PT</td>\n",
       "      <td>FS</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>AWS</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>F</td>\n",
       "      <td>FT</td>\n",
       "      <td>AWS</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>M</td>\n",
       "      <td>PT</td>\n",
       "      <td>DS</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>F</td>\n",
       "      <td>PT</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P007</td>\n",
       "      <td>M</td>\n",
       "      <td>FT</td>\n",
       "      <td>FS</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P008</td>\n",
       "      <td>F</td>\n",
       "      <td>-</td>\n",
       "      <td>FS</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P009</td>\n",
       "      <td>M</td>\n",
       "      <td>PT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P010</td>\n",
       "      <td>F</td>\n",
       "      <td>FT</td>\n",
       "      <td>DS</td>\n",
       "      <td>-</td>\n",
       "      <td>7.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P011</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender status  dept var1  var2 salary\n",
       "0   P001      M     FT    DS    2   8.0    NaN\n",
       "1   P002      F     PT    FS    3   NaN     54\n",
       "2   P003      M      -   AWS    5   5.0     59\n",
       "3   P004      F     FT   AWS  nan   8.0    120\n",
       "4   P005      M     PT    DS    7  11.0     58\n",
       "5   P006      F     PT  None    1   NaN     75\n",
       "6   P007      M     FT    FS  nan   NaN   None\n",
       "7   P008      F      -    FS   10   2.0    136\n",
       "8   P009      M     PT   NaN   14   3.0     60\n",
       "9   P010      F     FT    DS    -   7.0    125\n",
       "10  P011      M    NaN   AWS    6   9.0    NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas **``isnull()``**, and **``isna()``** methods are used to check and manage NULL values in a data frame. The function returns a boolean same-sized object indicating if the values are NA. NA values, such as None or numpy.NaN, gets mapped to True values. Everything else gets mapped to False values. \n",
    "\n",
    "Note: Characters such as empty strings '' or numpy.inf are not considered NA values (unless you set pandas.options.mode.use_inf_as_na = True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>status</th>\n",
       "      <th>dept</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  gender  status   dept   var1   var2  salary\n",
       "0   False   False   False  False  False  False    True\n",
       "1   False   False   False  False  False   True   False\n",
       "2   False   False   False  False  False  False   False\n",
       "3   False   False   False  False  False  False   False\n",
       "4   False   False   False  False  False  False   False\n",
       "5   False   False   False   True  False   True   False\n",
       "6   False   False   False  False  False   True    True\n",
       "7   False   False   False  False  False  False   False\n",
       "8   False   False   False   True  False  False   False\n",
       "9   False   False   False  False  False  False   False\n",
       "10  False   False    True  False  False  False    True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas **``notnull()``** and **``notna()``** functions detects existing/ non-missing values in the dataframe. The function returns a boolean object having the same size as that of the object on which it is applied, indicating whether each individual value is a na value or not. All of the non-missing values gets mapped to true and missing values get mapped to false. \n",
    "\n",
    "Note : Characters such as empty strings ‚Äù or numpy.inf are not considered NA values. (unless you set pandas.options.mode.use_inf_as_na = True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "status    1\n",
       "dept      2\n",
       "var1      0\n",
       "var2      3\n",
       "salary    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0.000000\n",
       "gender     0.000000\n",
       "status     9.090909\n",
       "dept      18.181818\n",
       "var1       0.000000\n",
       "var2      27.272727\n",
       "salary    27.272727\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üìù Note that there have been \"nan\" and \"-\" values whose data type is integer. They do NOOT look like as \"NaN\" in the DataFrame. üìù**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBdWnW3b98fk"
   },
   "source": [
    "## <p style=\"background-color:#9d4f8c; font-family:newtimeroman; color:#FFF9ED; font-size:175%; text-align:center; border-radius:10px 10px;\">Converting Inappropriate Values to NaN Values</p>\n",
    "\n",
    "<a id=\"3\"></a>\n",
    "<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" \n",
    "style=\"color:blue; background-color:#dfa8e4\" data-toggle=\"popover\">Content</a>\n",
    "\n",
    "- pd.to_numeric()\n",
    "- map()\n",
    "- replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They key here is the **``errors='coerce'``** parameter of to_numeric\n",
    "\n",
    "Per [the Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_numeric.html) it will replace any value which cannot be converted with **``NaN``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes:** When **``arg``** parameter is a dictionary, values in Series that are **NOT** in the dictionary (as keys) are converted to NaN. However, if the dictionary is a dict subclass that defines __missing__ (i.e. provides a method for default values), then this default is used rather than NaN [SOURCE](https://www.w3resource.com/pandas/series/series-map.php#:~:text=The%20map()%20function%20is,a%20dict%20or%20a%20Series.&text=Mapping%20correspondence.&text=If%20'ignore'%2C%20propagate%20NaN,them%20to%20the%20mapping%20correspondence.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everythings look like great with respect to inappropriate values. Before going further for applying handling methods for miising values, the categorical values in \"gender\" feature can be converted into numerical ones using map() method; however, it's up to you since you can come over this kind of issue later by applying various methods as well, such as get_dummies(), OneHot Encoding and Label Encoding techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djWju_X-PR9T"
   },
   "source": [
    "## <p style=\"background-color:#9d4f8c; font-family:newtimeroman; color:#FFF9ED; font-size:175%; text-align:center; border-radius:10px 10px;\">Missing Value Handling Methods</p>\n",
    "\n",
    "<a id=\"4\"></a>\n",
    "<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" \n",
    "style=\"color:blue; background-color:#dfa8e4\" data-toggle=\"popover\">Content</a>\n",
    "\n",
    " 1. <b>Deleting (Dropping) Rows</b> ----->if it has more than 70-75% of missing values\n",
    "    \n",
    " 2. <b>Replacing (Filling) With Mean/Median/Mode (Imputation)</b>--->can be applied on a feature which has numeric data\n",
    "\n",
    " 3. <b> Assigning An Unique Category</b>--->If a categorical feature has definite number of classes, we can assign another class\n",
    "    \n",
    " 4. <b>Predicting The Missing Values</b>---> we can predict the nulls with the help of a machine learning algorithm like linear regression\n",
    "\n",
    " 5. <b>Using Algorithms Which Support Missing Values</b>--->KNN is a machine learning algorithm which works on the principle of distance measure.  This algorithm can be used when there are nulls present in the dataset.  KNN considers the missing values by taking the majority of the K nearest values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_0xNPexDyzk"
   },
   "source": [
    " ## 1 - Dropping\n",
    " \n",
    " - dropna()\n",
    " - drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **``any``** : If any NA values are present, drop that row or column.\n",
    "* **``all``** : If all values are NA, drop that row or column [Source](https://www.journaldev.com/33492/pandas-dropna-drop-null-na-values-from-dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``thresh=N``** requires that a column has at least N **non-NaNs to survive.** [Source](https://stackoverflow.com/questions/51584906/thresh-in-dropna-for-dataframe-in-pandas-in-python/51584935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GmBZxqVDyzq"
   },
   "source": [
    " ## 2 - Filling Missing Values (Imputation)\n",
    " \n",
    "Before going ahead with imputation, let us remember what is a missing value. a missing value is the part of the dataset that seems missing or is a null value, maybe due to some missing data during research or data collection.\n",
    "\n",
    "Having a missing value in a machine learning model which will be your next step in your journey after Data Analytics is considered very inefficient and hazardous because of the following reasons:\n",
    "\n",
    "- Reduces the efficiency of the ML model.\n",
    "- Affects the overall distribution of data values.\n",
    "- It leads to a biased effect in the estimation of the ML model.\n",
    "\n",
    "By imputation, we mean to replace the missing or null values with a particular value in the entire dataset. Imputation can be done using any of the following basic techniques. In sum, Imputation methods are those where the missing data are filled in to create a complete data matrix that can be analyzed using standard methods.\n",
    " \n",
    " - **fillna()**\n",
    " - **where()**\n",
    " - **interpolate()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdUsVrEVDyzr"
   },
   "source": [
    " ### a.Filling with a specific value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2UjYRTMDyzt"
   },
   "source": [
    " ### b.Filling with any Proper Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**where() Replace values where the condition is False.**\n",
    "\n",
    "Pandas **``where()``** method is used to check a data frame for one or more condition and return the result accordingly. By default, it replaces the values of the rows where the condition evaluates to **False** with desired value. The **``where()``** method is the opposite of the The **``mask()``** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• **IMPORTANT :** The **``where()``** method assigns False places üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fill NaN values using an interpolation method.**\n",
    "\n",
    "**``interpolate()``** function in Pandas is basically used to fill NA values in the dataframe or series by generating points between given points. Therefore, this is a very powerful function to fill the missing values. It uses various interpolation techniques to fill the missing values rather than hard-coding the value.\n",
    "\n",
    "[How do pandas interpolate missing values?](https://note.nkmk.me/en/python-pandas-interpolate/)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.interpolate(\n",
    "                method: 'str' = 'linear',\n",
    "                axis: 'Axis' = 0,\n",
    "                limit: 'int | None' = None,\n",
    "                inplace: 'bool' = False,\n",
    "                limit_direction: 'str | None' = None,\n",
    "                limit_area: 'str | None' = None,\n",
    "                downcast: 'str | None' = None,\n",
    "                **kwargs,\n",
    "               ) -> 'DataFrame | None'\n",
    "Docstring:\n",
    "Fill NaN values using an interpolation method.\n",
    "\n",
    "Please note that only ``method='linear'`` is supported for DataFrame/Series with a MultiIndex.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "method : str, default 'linear'\n",
    "    Interpolation technique to use. One of:\n",
    "\n",
    "    * 'linear': Ignore the index and treat the values as equally\n",
    "      spaced. This is the only method supported on MultiIndexes.\n",
    "    * 'time': Works on daily and higher resolution data to interpolate\n",
    "      given length of interval.\n",
    "    * 'index', 'values': use the actual numerical values of the index.\n",
    "    * 'pad': Fill in NaNs using existing values.\n",
    "    * 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline',\n",
    "      'barycentric', 'polynomial': Passed to\n",
    "      `scipy.interpolate.interp1d`. These methods use the numerical\n",
    "      values of the index.  Both 'polynomial' and 'spline' require that\n",
    "      you also specify an `order` (int), e.g.\n",
    "      ``df.interpolate(method='polynomial', order=5)``.\n",
    "    * 'krogh', 'piecewise_polynomial', 'spline', 'pchip', 'akima',\n",
    "      'cubicspline': Wrappers around the SciPy interpolation methods of\n",
    "      similar names. See `Notes`.\n",
    "    * 'from_derivatives': Refers to\n",
    "      `scipy.interpolate.BPoly.from_derivatives` which\n",
    "      replaces 'piecewise_polynomial' interpolation method in\n",
    "      scipy 0.18.\n",
    "\n",
    "axis : {{0 or 'index', 1 or 'columns', None}}, default None\n",
    "    Axis to interpolate along.\n",
    "limit : int, optional\n",
    "    Maximum number of consecutive NaNs to fill. Must be greater than 0.\n",
    "inplace : bool, default False\n",
    "    Update the data in place if possible.\n",
    "limit_direction : {{'forward', 'backward', 'both'}}, Optional\n",
    "    Consecutive NaNs will be filled in this direction.\n",
    "\n",
    "    If limit is specified:\n",
    "        * If 'method' is 'pad' or 'ffill', 'limit_direction' must be 'forward'.\n",
    "        * If 'method' is 'backfill' or 'bfill', 'limit_direction' must be\n",
    "          'backwards'.\n",
    "\n",
    "    If 'limit' is not specified:\n",
    "        * If 'method' is 'backfill' or 'bfill', the default is 'backward'\n",
    "        * else the default is 'forward'\n",
    "\n",
    "    .. versionchanged:: 1.1.0\n",
    "        raises ValueError if `limit_direction` is 'forward' or 'both' and method is 'backfill' or 'bfill'.\n",
    "        raises ValueError if `limit_direction` is 'backward' or 'both' and method is 'pad' or 'ffill'.\n",
    "\n",
    "limit_area : {{`None`, 'inside', 'outside'}}, default None\n",
    "    If limit is specified, consecutive NaNs will be filled with this restriction.\n",
    "\n",
    "    * ``None``: No fill restriction.\n",
    "    * 'inside': Only fill NaNs surrounded by valid values (interpolate).\n",
    "    * 'outside': Only fill NaNs outside valid values (extrapolate).\n",
    "\n",
    "downcast : optional, 'infer' or None, defaults to None\n",
    "    Downcast dtypes if possible.\n",
    "``**kwargs`` : optional\n",
    "    Keyword arguments to pass on to the interpolating function.\n",
    "\n",
    "Returns\n",
    "-------\n",
    "Series or DataFrame or None\n",
    "    Returns the same object type as the caller, interpolated at some or all ``NaN`` values or None if ``inplace=True``.\n",
    "\n",
    "See Also\n",
    "--------\n",
    "fillna : Fill missing values using different methods.\n",
    "scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials (Akima interpolator).\n",
    "scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the Bernstein basis.\n",
    "scipy.interpolate.interp1d : Interpolate a 1-D function.\n",
    "scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh interpolator).\n",
    "scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic interpolation.\n",
    "scipy.interpolate.CubicSpline : Cubic spline data interpolator.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "The 'krogh', 'piecewise_polynomial', 'spline', 'pchip' and 'akima' methods are wrappers around the respective SciPy implementations of similar names. These use the actual numerical values of the index.\n",
    "For more information on their behavior, see the\n",
    "`SciPy documentation\n",
    "<https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation>`__and `SciPy tutorial\n",
    "<https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html>`__.\n",
    "\n",
    "Examples\n",
    "--------\n",
    "Filling in ``NaN`` in a :class:`~pandas.Series` via linear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about [interpolation](https://www.geeksforgeeks.org/python-pandas-dataframe-interpolate/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7Yy8BDdDyzy"
   },
   "source": [
    " ### c.Filling the Missing Values of Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **pad / ffill:** propagate last valid observation forward to next valid\n",
    "- **backfill / bfill:** use next valid observation to fill gap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJ8ijx7RDyzw"
   },
   "source": [
    " ### d.Filling by condition & by Group of the Categorical Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>status</th>\n",
       "      <th>dept</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>M</td>\n",
       "      <td>FT</td>\n",
       "      <td>DS</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>F</td>\n",
       "      <td>PT</td>\n",
       "      <td>FS</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>M</td>\n",
       "      <td>-</td>\n",
       "      <td>AWS</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P004</td>\n",
       "      <td>F</td>\n",
       "      <td>FT</td>\n",
       "      <td>AWS</td>\n",
       "      <td>nan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P005</td>\n",
       "      <td>M</td>\n",
       "      <td>PT</td>\n",
       "      <td>DS</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P006</td>\n",
       "      <td>F</td>\n",
       "      <td>PT</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P007</td>\n",
       "      <td>M</td>\n",
       "      <td>FT</td>\n",
       "      <td>FS</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P008</td>\n",
       "      <td>F</td>\n",
       "      <td>-</td>\n",
       "      <td>FS</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P009</td>\n",
       "      <td>M</td>\n",
       "      <td>PT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P010</td>\n",
       "      <td>F</td>\n",
       "      <td>FT</td>\n",
       "      <td>DS</td>\n",
       "      <td>-</td>\n",
       "      <td>7.0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P011</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender status  dept var1  var2 salary\n",
       "0   P001      M     FT    DS    2   8.0    NaN\n",
       "1   P002      F     PT    FS    3   NaN     54\n",
       "2   P003      M      -   AWS    5   5.0     59\n",
       "3   P004      F     FT   AWS  nan   8.0    120\n",
       "4   P005      M     PT    DS    7  11.0     58\n",
       "5   P006      F     PT  None    1   NaN     75\n",
       "6   P007      M     FT    FS  nan   NaN   None\n",
       "7   P008      F      -    FS   10   2.0    136\n",
       "8   P009      M     PT   NaN   14   3.0     60\n",
       "9   P010      F     FT    DS    -   7.0    125\n",
       "10  P011      M    NaN   AWS    6   9.0    NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's fill the missing values at \"status\" column with defined condition by \"salary\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî• **IMPORTANT :** Even if **``fillna()``** method has a inplace parameter, when inplace parameter are used with loc[ ] it does **NOT work** üî•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's fill the last missing value at \"status\" column with the mode of the group of \"gender\" and \"dept\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We couldn't fill missing value at the last row in the \"status\" column above because its corresponding value at the last row of the \"salary column has a NaN value as well. To fill this missing value at the \"status\" column, let's first examine the modes by grouping them by gender and department. Then we can decide which of the mod values we find to fill in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the transform() method returns the same length as input it is more logical to use the transform() method for feature engineering rather than using the apply() method. Otherwise, you will get NaN values in the new feature you created with apply() method. So the transform() method will be used to fill missing values in the DataFame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``Special Note:``** The index of df was RangeIndex(start=0, stop=2, step=1). Therefore, RangeIndex vs MultiIndex mismatach caused the issue.\n",
    "\n",
    "df.groupby([\"gender\", \"dept\"])[\"status\"].apply(lambda x : x.mode()).index\n",
    "\n",
    "**How to solve MultiIndex issue while using groupby() and apply()?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can groupy the 'gender' and 'dept' columns and then call apply on the df groupby object and pass the function mode. We can then call reset_index and pass param drop=True so that the multi-index is not added back as a column as you already have those columns:\n",
    "\n",
    "[How to group by mode in python?](https://stackoverflow.com/questions/30216921/how-to-group-by-mode-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's fill the missing values at \"salary\" column with the mean of the group of \"status\" and \"dept\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's fill the missing values at \"var1\" column with the mean of the group of \"gender\" and \"status\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's fill the missing values at \"var2\" column with the mean of group of \"status\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zorkPfI398gR"
   },
   "source": [
    "### e.Filling with Interpolation\n",
    "\n",
    "Pandas **``dataframe.interpolate()``** function is basically used to fill NA values in the dataframe or series. But, this is a very powerful function to fill the missing values. It uses various interpolation technique to fill the missing values rather than hard-coding the value [Source 01](https://www.geeksforgeeks.org/python-pandas-dataframe-interpolate/) & [Source 02](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "di5dNmNt98gS"
   },
   "outputs": [],
   "source": [
    "flights = sns.load_dataset(\"flights\")\n",
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#9d4f8c; font-size:150%; text-align:center; border-radius:10px 10px;\">The End of The Session - 07</p>\n",
    "\n",
    "<a id=\"5\"></a>\n",
    "<a href=\"#toc\" class=\"btn btn-primary btn-sm\" role=\"button\" aria-pressed=\"true\" \n",
    "style=\"color:blue; background-color:#dfa8e4\" data-toggle=\"popover\">Content</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\"><img src=\"https://i.ibb.co/99DQ3TY/DS-Courses.png\" class=\"img-fluid\" \n",
    "alt=\"CLRSWY\"></p>\n",
    "\n",
    "<a href=\"https://clarusway.com/\"><img align=\"center\" src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" alt=\"CLRSWY\" title=\"Way to Reinvent Yourself\"></a><br/>\n",
    "\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#9d4f8c; font-size:120%; text-align:center; border-radius:10px 10px;\">Way to Reinvent Yourself</p>\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DAwPy-S6 (Handling Missing Values, Outliers).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "231.475px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
